{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization :~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is a process that splits an input sequence into so called tokens.\n",
    "\n",
    "->One can think of token as a useful unit for semantic processing.\n",
    "\n",
    "->It can be a word, sentence, paragraph, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = \"Hello, I'm Parth Shingari!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello,', \"I'm\", 'Parth', 'Shingari!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of simple whitespace Tokenizer\n",
    "tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'I', \"'m\", 'Parth', 'Shingari', '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'I', \"'\", 'm', 'Parth', 'Shingari', '!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token normalization :~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we normalize a natural language resource, we attempt to reduce the randomness in it.\n",
    "\n",
    "When doing text normalization, we should know exactly what do we want to normalize and why. Also, the purpose of the input helps shaping the steps we’re going to apply to normalize our input. There are two things that we are interested in normalizing the most are *Sentence structure and Vocabulary*.\n",
    "\n",
    "In practice, we can do normalization over these two aspects by breaking into simpler problems like :\n",
    "\n",
    "→ Removal of duplicate whitespaces and punctuation.\n",
    "\n",
    "→ Removal or substitution of special characters/emojis.\n",
    "\n",
    "→ Substitution of contractions (very common in English; e.g.: ‘I’m’→‘I am’).\n",
    "\n",
    "→ Transform word numerals into numbers.\n",
    "\n",
    "→ Spell correction (one could say that a word can be misspelled infinite ways, so spell corrections reduce the vocabulary variation by “correcting”) — this is very important if you’re dealing with open user inputs, such as tweets, IMs and emails.\n",
    "\n",
    "→ Removal of gender/time/grade variation with Stemming or Lemmatization.\n",
    "\n",
    "→ Substitution of rare words for more common synonyms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming :~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. \n",
    "\n",
    "A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello , I 'm parth shingari !\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\" \".join(stemmer.stem(token) for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\LENOVO\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello , I 'm Parth Shingari !\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "stemmer = nltk.stem.WordNetLemmatizer()\n",
    "\" \".join(stemmer.lemmatize(token) for token in tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liked this project ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Star it on [github](https://github.com/parthshingari28/Text-Mining-and-Analytics-using-Python)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reach Out at !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[@parthshingari28](https://github.com/parthshingari28)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
